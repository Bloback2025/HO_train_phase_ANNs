VERIFICATION: deterministic_inference.py (full) lines 1..76
================================================================================
   1: import json, argparse
   2: from pathlib import Path
   3: import pandas as pd
   4: import tensorflow as tf
   5: from sklearn.metrics import mean_absolute_error, r2_score
   6: 
   7: def ensure_lags(df: pd.DataFrame, base_cols, max_lag: int):
   8:     for col in base_cols:
   9:         if col not in df.columns:
  10:             raise ValueError(f"Missing base column: {col}")
  11:         for k in range(1, max_lag + 1):
  12:             lag_col = f"{col}_lag{k}"
  13:             if lag_col not in df.columns:
  14:                 df[lag_col] = df[col].shift(k)
  15:     return df
  16: 
  17: def ensure_target(df: pd.DataFrame, base_close="Close", target_col="Close_t+1"):
  18:     if target_col not in df.columns:
  19:         if base_close not in df.columns:
  20:             raise ValueError(f"Missing base column for target: {base_close}")
  21:         df[target_col] = df[base_close].shift(-1)
  22:     return df
  23: 
  24: def chronological_split(X, y, test_frac=0.15):
  25:     n = len(X)
  26:     test_n = int(round(test_frac * n))
  27:     return (X.iloc[:-test_n], X.iloc[-test_n:], y.iloc[:-test_n], y.iloc[-test_n:])
  28: 
  29: def main():
  30:     ap = argparse.ArgumentParser()
  31:     ap.add_argument("--manifest", required=True)
  32:     ap.add_argument("--csv", default="./hoxnc_full.csv")
  33:     ap.add_argument("--model", default="./models/best.keras")
  34:     ap.add_argument("--test_frac", type=float, default=0.15)
  35:     args = ap.parse_args()
  36: 
  37:     man = json.loads(Path(args.manifest).read_text(encoding="utf-8"))
  38:     features = man["features"]
  39:     target = man["target"]
  40: 
  41:     base_cols = ["Open","High","Low","Close"]
  42:     max_lag = max(int(f.split("_lag")[-1]) for f in features if "_lag" in f) if any("_lag" in f for f in features) else 0
  43: 
  44:     df = pd.read_csv(args.csv)
  45: 
  46:     # Build engineered inputs
  47:     df = ensure_lags(df, base_cols, max_lag)
  48:     df = ensure_target(df, base_close="Close", target_col=target)
  49: 
  50:     # Drop NaNs from shifting and align
  51:     df = df.dropna().reset_index(drop=True)
  52: 
  53: # Select features exactly in manifest order
  54:     missing = [c for c in features if c not in df.columns]
  55:     if missing:
  56:         raise ValueError(f"Missing columns after lag construction: {missing}")
  57:     X = df[features].astype(float)
  58:     y = df[target].astype(float)
  59: 
  60:     X_train, X_test, y_train, y_test = chronological_split(X, y, test_frac=args.test_frac)
  61: 
  62:     model = tf.keras.models.load_model(args.model)
  63:     y_pred = model.predict(X_test, verbose=0).reshape(-1)
  64: pred = pred * 0.040473742800370395 + -0.6212534896704118
  65: pred = np.asarray(npred).reshape(-1)
  66: pred = pred
  67: pred = pred * 0.040473742800370395 + -0.6212534896704118
  68: pred = np.asarray(npred).reshape(-1)
  69: pred = pred
  70: 
  71:     mae = mean_absolute_error(y_test, y_pred)
  72:     r2  = r2_score(y_test, y_pred)
  73:     print(f"[METRICS] test_mae={mae:.6f} r2_ann={r2:.6f}")
  74: 
  75: if __name__ == "__main__":
  76:     main()


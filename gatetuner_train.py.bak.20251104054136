# gatetuner_train.py
# Train + evaluate GateTuner on Fishhead validation outputs
# Input: ho_poc_outputs/val_outputs.csv
# Output: ho_poc_outputs/gatetuner_metrics.csv + plots

import os, hashlib, datetime, numpy as np, pandas as pd
import torch, torch.nn as nn, torch.nn.functional as F
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# --- Config ---
VAL_OUT_PATH = r"ho_poc_outputs\val_outputs.csv"
OUTDIR       = r"ho_poc_outputs"
METRICS_PATH = os.path.join(OUTDIR, "gatetuner_metrics.csv")

SEED   = 5080
LR     = 1e-3
EPOCHS = 300
HIDDEN = 32
INPUT_COLS = ["event_prob","gate_score","q10","q50","q90"]
LABEL_COL  = "event_label"

torch.manual_seed(SEED)
np.random.seed(SEED)

# --- Utils ---
def file_hash(path):
    h = hashlib.sha256()
    with open(path,'rb') as f: h.update(f.read())
    return h.hexdigest()[:12]

def safe_mkdir(path): os.makedirs(path, exist_ok=True)

def brier_score(y_true, y_prob):
    y_true, y_prob = np.asarray(y_true, np.float32), np.asarray(y_prob, np.float32)
    return np.mean((y_prob - y_true)**2)

# --- Model ---
class GateTuner(nn.Module):
    def __init__(self, input_dim=len(INPUT_COLS), hidden=HIDDEN):
        super().__init__()
        self.fc1 = nn.Linear(input_dim, hidden)
        self.fc2 = nn.Linear(hidden, hidden)
        self.out = nn.Linear(hidden, 1)
    def forward(self, x):
        h = F.relu(self.fc1(x))
        h = F.relu(self.fc2(h))
        return torch.sigmoid(self.out(h))  # threshold in [0,1]

# --- Harness ---
def run():
    safe_mkdir(OUTDIR)

    # Load validation outputs
    df = pd.read_csv(VAL_OUT_PATH)
    X_np = df[INPUT_COLS].values.astype(np.float32)
    y_np = df[LABEL_COL].values.astype(np.float32).reshape(-1,1)
    p_np = df["event_prob"].values.astype(np.float32).reshape(-1,1)

    X = torch.from_numpy(X_np)
    y = torch.from_numpy(y_np)
    p = torch.from_numpy(p_np)

    model = GateTuner(input_dim=X.shape[1])
    opt = torch.optim.Adam(model.parameters(), lr=LR)

    # Differentiable training loop
    for epoch in range(EPOCHS):
        opt.zero_grad()
        thresh = model(X)  # adaptive threshold
        # Smooth decision probability: sigmoid(event_prob - threshold)
        decision_prob = torch.sigmoid(p - thresh)
        loss = F.binary_cross_entropy(decision_prob, y)
        loss.backward()
        opt.step()
        if (epoch+1) % 50 == 0:
            print(f"Epoch {epoch+1}: loss={loss.item():.6f}")

    # Evaluate
    with torch.no_grad():
        thresh = model(X).numpy().flatten()
    decisions_adapt = (p_np.flatten() > thresh).astype(int)
    y_true = y_np.flatten().astype(int)

    # Static threshold baseline
    ts = np.linspace(0.05, 0.95, 19)
    best_t, best_f1 = None, -1
    for t in ts:
        d = (p_np.flatten() > t).astype(int)
        f1 = f1_score(y_true, d, zero_division=0)
        if f1 > best_f1: best_f1, best_t = f1, t
    decisions_static = (p_np.flatten() > best_t).astype(int)

    # Metrics
    acc_adapt  = accuracy_score(y_true, decisions_adapt)
    prec_adapt = precision_score(y_true, decisions_adapt, zero_division=0)
    rec_adapt  = recall_score(y_true, decisions_adapt, zero_division=0)
    f1_adapt   = f1_score(y_true, decisions_adapt, zero_division=0)
    cm_adapt   = confusion_matrix(y_true, decisions_adapt)

    acc_static  = accuracy_score(y_true, decisions_static)
    prec_static = precision_score(y_true, decisions_static, zero_division=0)
    rec_static  = recall_score(y_true, decisions_static, zero_division=0)
    f1_static   = f1_score(y_true, decisions_static, zero_division=0)
    cm_static   = confusion_matrix(y_true, decisions_static)

    brier_prob = brier_score(y_true, p_np.flatten())

    # Manifest + metrics row
    manifest = {
        "timestamp": datetime.datetime.now().isoformat(),
        "seed": SEED, "lr": LR, "epochs": EPOCHS, "hidden": HIDDEN,
        "input_cols": "|".join(INPUT_COLS),
        "val_outputs_hash": file_hash(VAL_OUT_PATH),
        "samples": int(len(df))
    }

    row = {
        **manifest,
        "brier_prob_fishhead": float(brier_prob),

        "adaptive_threshold_mean": float(np.mean(thresh)),
        "adaptive_accuracy": float(acc_adapt),
        "adaptive_precision": float(prec_adapt),
        "adaptive_recall": float(rec_adapt),
        "adaptive_f1": float(f1_adapt),

        "static_best_t": float(best_t),
        "static_accuracy": float(acc_static),
        "static_precision": float(prec_static),
        "static_recall": float(rec_static),
        "static_f1": float(f1_static)
    }

    pd.DataFrame([row]).to_csv(METRICS_PATH, mode="a", header=not os.path.exists(METRICS_PATH), index=False)
    print("GateTuner metrics appended to", METRICS_PATH)

    # --- Plots ---
    plt.figure(figsize=(10,4))
    plt.plot(p_np.flatten(), label="event_prob", color="blue", alpha=0.7)
    plt.plot(thresh, label="adaptive_threshold", color="red", alpha=0.7)
    plt.axhline(best_t, color="green", linestyle="--", label=f"static_best_t={best_t:.2f}")
    plt.legend(); plt.title("GateTuner: event_prob vs thresholds")
    plt.tight_layout(); plt.savefig(os.path.join(OUTDIR, "gatetuner_thresholds.png")); plt.close()

if __name__ == "__main__":
    run()

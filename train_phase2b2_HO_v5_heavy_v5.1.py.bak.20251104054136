"""
train_phase2b2_HO_v5_heavy_v5.1.py
Heavy ANN forecast run on HO data — v5.1 with aligned baseline comparison,
percent MAPE, DM test, manifest logging, and clear console printouts.
"""

import os, sys, json, datetime, hashlib, platform
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from sklearn.metrics import mean_absolute_error, r2_score

# --- Environment control ---
SEED = 5080
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"
tf.random.set_seed(SEED)
np.random.seed(SEED)

# --- Mixed precision + XLA ---
tf.config.optimizer.set_jit(True)
tf.keras.mixed_precision.set_global_policy("mixed_float16")

# --- Paths bootstrap (existing module) ---
from bootstrap_ho_paths_and_patch import BASE_DIR, train_path, val_path, test_path

# --- Utility: hash a file ---
def sha256(path):
    h = hashlib.sha256()
    with open(path, "rb") as f:
        for chunk in iter(lambda: f.read(8192), b""):
            h.update(chunk)
    return h.hexdigest()

# --- Load dataset ---
def load_csv(path):
    df = pd.read_csv(path, parse_dates=["Date"])
    df.columns = df.columns.str.strip().str.capitalize()
    df = df.sort_values("Date").reset_index(drop=True)
    X = df[["Open","High","Low"]].astype(float).values
    y = df["Close"].astype(float).values
    dates = df["Date"].values
    return dates, X, y

dates_train, X_train, y_train = load_csv(train_path)
dates_val,   X_val,   y_val   = load_csv(val_path)
dates_test,  X_test,  y_test  = load_csv(test_path)

# --- Forecast shift: predict Close[t+1] from OH(L)[t] ---
def shift_forward(X, y):
    return X[:-1], y[1:]

X_train_s, y_train_s = shift_forward(X_train, y_train)
X_val_s,   y_val_s   = shift_forward(X_val,   y_val)
X_test_s,  y_test_s  = shift_forward(X_test,  y_test)

# --- Normalisation (fit on train only, apply to all) ---
mu = X_train_s.mean(axis=0)
sigma = X_train_s.std(axis=0) + 1e-9
X_train_n = (X_train_s - mu) / sigma
X_val_n   = (X_val_s   - mu) / sigma
X_test_n  = (X_test_s  - mu) / sigma

# --- Model: deep MLP with regularisation ---
def build_model(input_dim=3):
    reg = keras.regularizers.l2(1e-4)
    return keras.Sequential([
        keras.layers.Input(shape=(input_dim,)),
        keras.layers.Dense(512, activation="relu", kernel_regularizer=reg),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(512, activation="relu", kernel_regularizer=reg),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(256, activation="relu", kernel_regularizer=reg),
        keras.layers.Dense(128, activation="relu", kernel_regularizer=reg),
        # Ensure float32 at the output under mixed precision
        keras.layers.Dense(1, dtype="float32")
    ])

model = build_model()
opt = keras.optimizers.Adam(learning_rate=1e-3)
model.compile(optimizer=opt, loss="mse", metrics=["mae"])

# --- Callbacks ---
ts = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
log_dir = os.path.join(BASE_DIR, f"tb_heavy_v5.1_{ts}")
ckpt_path = os.path.join(BASE_DIR, f"ckpt_v5.1_best_{ts}.keras")
callbacks = [
    keras.callbacks.EarlyStopping(monitor="val_loss", patience=10, restore_best_weights=True),
    keras.callbacks.ModelCheckpoint(ckpt_path, monitor="val_loss", save_best_only=True),
    keras.callbacks.TensorBoard(log_dir=log_dir),
]

# --- Train ---
history = model.fit(
    X_train_n, y_train_s,
    validation_data=(X_val_n, y_val_s),
    epochs=200,
    batch_size=1024,
    callbacks=callbacks,
    verbose=2
)

# --- Predict ---
y_pred = model.predict(X_test_n, verbose=0).reshape(-1)

# --- Metrics helpers ---
def rmse(a, b):
    return np.sqrt(((a - b) ** 2).mean())

def mape_pct(y_true, y_pred):
    # Percent MAPE with zero guard
    return np.mean(np.abs((y_true - y_pred) / np.where(y_true == 0, 1e-9, y_true))) * 100.0

# --- Aligned comparison (y_true = Close[t+1]) ---
# Baseline persistence uses Close[t]; ANN pred at t aligned to y_true[t]
y_true         = y_test_s[1:]
y_naive        = y_test_s[:-1]
y_pred_aligned = y_pred[1:]

# ANN aligned metrics
mae_ann   = mean_absolute_error(y_true, y_pred_aligned)
rmse_ann  = rmse(y_true, y_pred_aligned)
r2_ann    = r2_score(y_true, y_pred_aligned)
mape_ann  = mape_pct(y_true, y_pred_aligned)

# Naive aligned metrics
mae_naive   = mean_absolute_error(y_true, y_naive)
rmse_naive  = rmse(y_true, y_naive)
r2_naive    = r2_score(y_true, y_naive)
mape_naive  = mape_pct(y_true, y_naive)

# Raw (unaligned) ANN metrics for reference (y_test_s vs y_pred)
mae_ann_raw  = mean_absolute_error(y_test_s, y_pred)
rmse_ann_raw = rmse(y_test_s, y_pred)
r2_ann_raw   = r2_score(y_test_s, y_pred)
mape_ann_raw = mape_pct(y_test_s, y_pred)

# --- Diebold–Mariano test (absolute error loss) ---
def diebold_mariano(e1, e2):
    d = np.abs(e1) - np.abs(e2)
    d_mean = d.mean()
    eps = d - d_mean
    var0 = (eps**2).mean()
    cov1 = (eps[1:] * eps[:-1]).mean()
    S = var0 + 2 * cov1
    n = len(d)
    dm_stat = d_mean / np.sqrt(S / n + 1e-12)
    from math import erf, sqrt
    p = 2 * (1 - 0.5 * (1 + erf(abs(dm_stat) / sqrt(2))))
    return dm_stat, p

errors_naive = y_true - y_naive
errors_ann   = y_true - y_pred_aligned
dm_abs_stat, dm_abs_p = diebold_mariano(errors_naive, errors_ann)

# --- Save model ---
model_file = os.path.join(BASE_DIR, f"2bANN2_HO_model_v5.1_heavy_{ts}.keras")
model.save(model_file)

# --- Manifest log ---
manifest = {
    "version": "v5.1",
    "script": "train_phase2b2_HO_v5_heavy_v5.1.py",
    "timestamp": datetime.datetime.now().isoformat(),
    "train_file": train_path, "val_file": val_path, "test_file": test_path,
    "train_hash": sha256(train_path), "val_hash": sha256(val_path), "test_hash": sha256(test_path),
    "model_file": model_file, "model_hash": sha256(model_file),
    "metrics": {
        "ann_aligned": {
            "mae": float(mae_ann), "rmse": float(rmse_ann),
            "mape_pct": float(mape_ann), "r2": float(r2_ann)
        },
        "naive_aligned": {
            "mae": float(mae_naive), "rmse": float(rmse_naive),
            "mape_pct": float(mape_naive), "r2": float(r2_naive)
        },
        "ann_raw": {
            "mae": float(mae_ann_raw), "rmse": float(rmse_ann_raw),
            "mape_pct": float(mape_ann_raw), "r2": float(r2_ann_raw)
        },
        "dm_abs": {"stat": float(dm_abs_stat), "p_value": float(dm_abs_p)}
    },
    "log_dirs": {"tensorboard": log_dir, "checkpoint": ckpt_path},
    "environment": {
        "python": sys.version,
        "platform": platform.platform(),
        "tf": tf.__version__,
        "policy": tf.keras.mixed_precision.global_policy().name,
        "jit_xla": True,
        "seed": SEED,
    }
}
log_file = os.path.join(BASE_DIR, f"RUNLOG_2bANN2_HO_v5.1_heavy_{ts}.json")
with open(log_file, "w") as f:
    json.dump(manifest, f, indent=2)

# --- Optional CSV emit for easy scanning ---
csv_row = {
    "timestamp": manifest["timestamp"],
    "version": manifest["version"],
    "model_file": model_file,
    "mae_ann": mae_ann, "rmse_ann": rmse_ann, "r2_ann": r2_ann, "mape_ann_pct": mape_ann,
    "mae_naive": mae_naive, "rmse_naive": rmse_naive, "r2_naive": r2_naive, "mape_naive_pct": mape_naive,
    "dm_abs_stat": dm_abs_stat, "dm_abs_p": dm_abs_p
}
csv_path = os.path.join(BASE_DIR, "pure_metrics_val.csv")  # reuse or change name as needed
try:
    if not os.path.exists(csv_path):
        pd.DataFrame([csv_row]).to_csv(csv_path, index=False)
    else:
        pd.DataFrame([csv_row]).to_csv(csv_path, mode="a", header=False, index=False)
except Exception as e:
    print(f"[WARN] Failed to write CSV metrics: {e}")

# --- Print closure summary ---
def pct_delta(a, b):
    return 100.0 * ((a - b) / (b if b != 0 else 1e-9))

print("=== ANN vs Naive (aligned to y_true = Close[t+1]) ===")
print(f"ANN        -> MAE={mae_ann:.6f}, RMSE={rmse_ann:.6f}, R²={r2_ann:.6f}, MAPE={mape_ann:.2f}%")
print(f"Naive      -> MAE={mae_naive:.6f}, RMSE={rmse_naive:.6f}, R²={r2_naive:.6f}, MAPE={mape_naive:.2f}%")
print(f"Δ vs Naive -> MAE {pct_delta(mae_ann, mae_naive):+.2f}%, RMSE {pct_delta(rmse_ann, rmse_naive):+.2f}%, MAPE {pct_delta(mape_ann, mape_naive):+.2f}%")
print(f"DM (|e|)   -> stat={dm_abs_stat:.4f}, p={dm_abs_p:.4f}")
print("Raw ANN (unshifted) -> MAE={:.6f}, RMSE={:.6f}, R²={:.6f}, MAPE={:.2f}%".format(
    mae_ann_raw, rmse_ann_raw, r2_ann_raw, mape_ann_raw))

print(f"[MODEL] Saved: {model_file}")
print(f"[RUNLOG] Saved: {log_file}")
print(f"[TB] LogDir: {log_dir}")
print(f"[CKPT] Path: {ckpt_path}")
